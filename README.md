# Tic-Tac-Toe AI (5 в ряд на поле 10x10)

Добро пожаловать в репозиторий **Tic-Tac-Toe AI**!  
Здесь вы найдёте реализацию популярной игры «Крестики-нолики» на поле **10x10** с условием победы при **5 в ряд**, дополненную простым обучением с подкреплением на базе **PyTorch** и визуализацией при помощи **Pygame**.

<p align="center">
  <img width="400" src="https://user-images.githubusercontent.com/25181517/183357849-86f72a59-fbfc-49a0-b28d-3b2fce5a8c6e.png" alt="Tic Tac Toe 5 in a row">
</p>

---

## Оглавление
1. [Особенности проекта](#особенности-проекта)
2. [Используемые технологии](#используемые-технологии)
3. [Установка и запуск](#установка-и-запуск)
4. [Принцип работы](#принцип-работы)
5. [Структура репозитория](#структура-репозитория)
6. [Возможности для доработки](#возможности-для-доработки)
7. [Обратная связь](#обратная-связь)
8. [Лицензия](#лицензия)

---

## Особенности проекта
- **Расширенное поле**: 10x10 вместо классических 3x3.
- **Нейронная сеть**: использует `PyTorch` для оценки выгодности ходов.
- **Обучение с подкреплением**: каждое действие вознаграждается или наказывается, что позволяет модели учиться более осмысленной стратегии.
- **Визуализация**: библиотека `Pygame` отображает текущую доску, ходы и процесс игры.
- **Награда за победу / ничью / проигрыш**:
  - **Победа**: `+1`
  - **Ничья**: `+0.5`
  - **Проигрыш**: `-1`

---

## Используемые технологии
- [**Python**](https://www.python.org/) — основной язык разработки
- [**NumPy**](https://numpy.org/) — для удобной работы с массивами и матрицами
- [**PyTorch**](https://pytorch.org/) — фреймворк для создания и обучения нейронных сетей
- [**Pygame**](https://www.pygame.org/) — для визуализации игрового поля
- [**random**](https://docs.python.org/3/library/random.html) — для выбора случайных ходов соперника
- [**torch.optim**](https://pytorch.org/docs/stable/optim.html) — оптимизатор (Adam) для обучения сети
- [**torch.nn**](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) — слои и функции потерь (MSE) для нейросети

---

## Установка и запуск

### 1. Клонирование репозитория
```bash
git clone https://github.com/ваш-логин/tic-tac-toe-ai-10x10.git
cd tic-tac-toe-ai-10x10
```

### 2. Создание и активация виртуального окружения (рекомендуется)
```bash
python -m venv venv
# Для Windows:
venv\Scripts\activate
# Для macOS / Linux:
source venv/bin/activate
```

### 3. Установка зависимостей
```bash
pip install -r requirements.txt
```
> **Примечание**: убедитесь, что у вас установлены Python (3.7+) и pip.  
> Если зависимостей немного и они не вынесены в файл `requirements.txt`, установите их вручную:
> ```bash
> pip install numpy torch pygame
> ```

### 4. Запуск проекта
```bash
python main.py
```
> После запуска откроется окно Pygame с игрой. В терминале/консоли будет отражаться прогресс обучения по эпизодам.

---

## Принцип работы

1. **Инициализация**  
   Создаётся доска размера `10x10`, полностью заполненная нулями (0 означает пустую клетку).
   
2. **Нейронная сеть**  
   - Входной слой: `BOARD_SIZE * BOARD_SIZE = 100` входов (каждая клетка кодируется числом).
   - Скрытые слои: два по 128 нейронов с функцией активации ReLU.
   - Выходной слой: `100` нейронов, по одному на каждую клетку (представляет **Q-значение** для каждого возможного хода).

3. **Обучение с подкреплением**  
   - После каждого хода вычисляется награда: `WIN_REWARD`, `DRAW_REWARD` или `LOSE_REWARD`.
   - Используется **Q-learning**:
     \[
     Q(s, a) \leftarrow Q(s, a) + \alpha \, \bigl[r + \gamma \max_{a'} Q(s', a') - Q(s, a)\bigr]
     \]
   - Оптимизатор **Adam** с функцией потерь **MSE** минимизирует разницу между предсказанными Q-значениями и целевыми.

4. **Игровой процесс**  
   - Игрок `1` (AI) выбирает ход согласно стратегии (берёт **argmax** по Q-значениям).
   - Игрок `2` (случайный выбор) ставит «крестик» в любую свободную клетку.
   - Проверяется, сформированы ли 5 в ряд:
     - по горизонтали,
     - по вертикали,
     - по диагонали и \ или против диагонали.
   - Переход к следующему состоянию и повтор шага обучения (обновление Q-значений).

---

## Структура репозитория

```
tic-tac-toe-ai-10x10/
├── main.py               # Основной скрипт с игрой и логикой обучения
├── requirements.txt      # Список необходимых зависимостей (при наличии)
├── README.md             # Текущий файл README
└── assets/               # (опционально) изображения, иконки и др. ресурсы
```

---

## Возможности для доработки
1. **Добавить функцию сохранения модели** после обучения.
2. **Реализовать нагрузочное тестирование** (например, через несколько тысяч партий).
3. **Сделать противника умнее**: вместо случайных ходов использовать алгоритмы минимакса, MCTS или другую нейронную сеть.
4. **Графический интерфейс**: добавить меню, кнопки «Начать заново», «Выход» и др.
5. **Многопоточность**: параллельно запускать несколько партий, ускоряя обучение.

---

## Обратная связь
Если у вас возникли вопросы, идеи или предложения по улучшению проекта, будем рады обратной связи:
- Открывайте **Issue** в данном репозитории.
- Или пишите напрямую: [email@example.com](mailto:email@example.com).

---

## Лицензия
Данный проект распространяется по лицензии **MIT**. Свободно используйте, изменяйте и дополняйте код для любых целей.

<p align="center">
  Сделано с любовью и увлечённостью к AI и играм!  
</p>
